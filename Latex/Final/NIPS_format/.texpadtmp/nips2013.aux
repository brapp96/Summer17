\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{NodeEmbed}
\citation{word2vec}
\citation{word2vec}
\citation{NodeEmbed}
\citation{LevyGoldberg}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{NodeEmbed}
\citation{Alon}
\citation{NBT-Ihara}
\citation{Lovasz}
\citation{Luxburg}
\citation{Lovasz}
\@writefile{toc}{\contentsline {section}{\numberline {2}Description}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Notation}{2}{subsection.2.1}}
\citation{word2vec}
\citation{NodeEmbed}
\citation{Alon}
\citation{NBT-Ihara}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Algorithm}{3}{subsection.2.2}}
\citation{Lovasz}
\citation{NBT-Ihara}
\citation{NBT-Ihara}
\citation{NBT-Ihara}
\citation{NBT-Ihara}
\citation{Alon}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theory}{4}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical Results}{5}{section.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:subim11}{{1a}{6}{1000 nodes\relax }{figure.caption.1}{}}
\newlabel{sub@fig:subim11}{{a}{6}{1000 nodes\relax }{figure.caption.1}{}}
\newlabel{fig:subim12}{{1b}{6}{2000 nodes\relax }{figure.caption.1}{}}
\newlabel{sub@fig:subim12}{{b}{6}{2000 nodes\relax }{figure.caption.1}{}}
\newlabel{fig:subim13}{{1c}{6}{5000 nodes\relax }{figure.caption.1}{}}
\newlabel{sub@fig:subim13}{{c}{6}{5000 nodes\relax }{figure.caption.1}{}}
\newlabel{fig:subim14}{{1d}{6}{10000 nodes\relax }{figure.caption.1}{}}
\newlabel{sub@fig:subim14}{{d}{6}{10000 nodes\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \emph  {Performance of both algorithms as a function of sparsity. We show performance for four differently-sized graphs. Note that error in measurement is also noticeably lower for VEC-NBT than for VEC.}\relax }}{6}{figure.caption.1}}
\newlabel{fig:image1}{{1}{6}{\emph {Performance of both algorithms as a function of sparsity. We show performance for four differently-sized graphs. Note that error in measurement is also noticeably lower for VEC-NBT than for VEC.}\relax }{figure.caption.1}{}}
\citation{NodeEmbed}
\newlabel{fig:subim21}{{2a}{7}{average degree 5\relax }{figure.caption.2}{}}
\newlabel{sub@fig:subim21}{{a}{7}{average degree 5\relax }{figure.caption.2}{}}
\newlabel{fig:subim22}{{2b}{7}{average degree 10\relax }{figure.caption.2}{}}
\newlabel{sub@fig:subim22}{{b}{7}{average degree 10\relax }{figure.caption.2}{}}
\newlabel{fig:subim23}{{2c}{7}{average degree 15\relax }{figure.caption.2}{}}
\newlabel{sub@fig:subim23}{{c}{7}{average degree 15\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \emph  {Performance of both algorithms as the number of nodes increases from 100 to 10000. Note that the x-axis here is the number of nodes and the average degree is constant for each graph, and we show the results for three graphs with different sparsities.}\relax }}{7}{figure.caption.2}}
\newlabel{fig:image2}{{2}{7}{\emph {Performance of both algorithms as the number of nodes increases from 100 to 10000. Note that the x-axis here is the number of nodes and the average degree is constant for each graph, and we show the results for three graphs with different sparsities.}\relax }{figure.caption.2}{}}
\newlabel{fig:subim31}{{3a}{7}{5 step random walks\relax }{figure.caption.3}{}}
\newlabel{sub@fig:subim31}{{a}{7}{5 step random walks\relax }{figure.caption.3}{}}
\newlabel{fig:subim32}{{3b}{7}{10 step random walks\relax }{figure.caption.3}{}}
\newlabel{sub@fig:subim32}{{b}{7}{10 step random walks\relax }{figure.caption.3}{}}
\newlabel{fig:subim33}{{3c}{7}{20 step random walks\relax }{figure.caption.3}{}}
\newlabel{sub@fig:subim33}{{c}{7}{20 step random walks\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \emph  {Performance of both algorithms as the random walks increase in length, from 5 to 20 steps. Here we are again plotting as a function of sparsity, but we show that the curve moves rightward as the length of the walks increase. We also show the improvement between backtracking and non-backtracking random walks is more visible for shorter walks.}\relax }}{7}{figure.caption.3}}
\newlabel{fig:image3}{{3}{7}{\emph {Performance of both algorithms as the random walks increase in length, from 5 to 20 steps. Here we are again plotting as a function of sparsity, but we show that the curve moves rightward as the length of the walks increase. We also show the improvement between backtracking and non-backtracking random walks is more visible for shorter walks.}\relax }{figure.caption.3}{}}
\newlabel{fig:subim41}{{4a}{7}{2 clusters\relax }{figure.caption.4}{}}
\newlabel{sub@fig:subim41}{{a}{7}{2 clusters\relax }{figure.caption.4}{}}
\newlabel{fig:subim42}{{4b}{7}{3 clusters\relax }{figure.caption.4}{}}
\newlabel{sub@fig:subim42}{{b}{7}{3 clusters\relax }{figure.caption.4}{}}
\newlabel{fig:subim43}{{4c}{7}{5 clusters\relax }{figure.caption.4}{}}
\newlabel{sub@fig:subim43}{{c}{7}{5 clusters\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \emph  {Performance of both algorithms as the number of clusters increases from 2 to 5. Performance is drastically lowered on anything larger than 2 graphs, but the improvement of using non-backtracking random walks is still clearly visible.}\relax }}{7}{figure.caption.4}}
\newlabel{fig:image4}{{4}{7}{\emph {Performance of both algorithms as the number of clusters increases from 2 to 5. Performance is drastically lowered on anything larger than 2 graphs, but the improvement of using non-backtracking random walks is still clearly visible.}\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{7}{section.5}}
\bibstyle{apalike}
\bibdata{biblio.bib}
\bibcite{Alon}{Alon et\nobreakspace  {}al., 2007}
\bibcite{NodeEmbed}{Ding et\nobreakspace  {}al., 2016}
\bibcite{NBT-Ihara}{Kempton, 2016}
\bibcite{LevyGoldberg}{Levy and Goldberg, 2014}
\bibcite{Lovasz}{Lov{\'{a}}sz, 1993}
\bibcite{Luxburg}{Luxburg, 2006}
\bibcite{word2vec}{Mikolov et\nobreakspace  {}al., 2013}
